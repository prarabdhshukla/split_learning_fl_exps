{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a56cf463",
   "metadata": {},
   "source": [
    "<center><h1> FLamby integration into Fed-BioMed </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e1352",
   "metadata": {},
   "source": [
    "This notebook highlights practical use cases for the FLamby integration into Fed-BioMed. A few datasets are here tested:\n",
    "1. IXI Tiny\n",
    "2. Heart-Disease\n",
    "3. TCGA-BRCA\n",
    "4. Synthetic\n",
    "5. ISIC\n",
    "\n",
    "For one FLamby dataset (LIDC-IDRI), we noticed conflicts over few packages including Torch, which cannot be easily resolved by changing package versions but need changes in the code (either on FLamby or Fed-BioMed side). This situation shows a certain complexity regarding the interoperability and has to be taken into account for future datasets that will be part of the suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d89cd",
   "metadata": {},
   "source": [
    "## 1. Fed-IXI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from flamby.datasets.fed_ixi import (Baseline as ixi_baseline,\n",
    "                                     BaselineLoss as ixi_baseline_loss,\n",
    "                                     Optimizer as ixi_optimizer,\n",
    "                                     BATCH_SIZE as ixi_batch_size,\n",
    "                                     LR as ixi_lr)\n",
    "\n",
    "class UNetTrainingPlan(TorchTrainingPlan):\n",
    "    # Init of UNetTrainingPlan\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(UNetTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = ixi_baseline() # UNet model\n",
    "        self.loss = ixi_baseline_loss() # Dice loss\n",
    "        \n",
    "        deps = ['from torch.optim import AdamW',\n",
    "               'from flamby.datasets.fed_ixi import (Baseline as ixi_baseline,\\\n",
    "                BaselineLoss as ixi_baseline_loss,\\\n",
    "                Optimizer as ixi_optimizer)',]\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = ixi_optimizer(self.parameters()) # AdamW\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, img, target):\n",
    "        #this function must return the loss to backward it \n",
    "        output = self.forward(img)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dac8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': ixi_batch_size,\n",
    "    'lr': ixi_lr,\n",
    "    'epochs': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e2dc5",
   "metadata": {},
   "source": [
    "*train_transform_flamby* key in **training_args** can optionally be used to perform extra transformations on a flamby dataset.\n",
    "\n",
    "As a reminder, flamby datasets are already internally handling a transformation through their dataloader (this internal transform\n",
    "is the one officially used for the flamby benchmark). Thus, one should check what is already performed on the flamby side before\n",
    "adding transforms through the researcher.\n",
    "\n",
    "*train_transform_flamby* has to be defined as a list containing two elements:\n",
    "- the first is the imports needed to perform the transformation\n",
    "- the second is the Compose object that will be used to input the transform parameter of the flamby dataset federated class\n",
    "\n",
    "Example:\n",
    "```python\n",
    "training_args = {\n",
    "    ...,\n",
    "    'train_transform_flamby':[\"from monai.transforms import (Compose, NormalizeIntensity, Resize,)\",\n",
    "                         \"Compose([Resize((48,60,48)), NormalizeIntensity()])\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c6215",
   "metadata": {},
   "source": [
    "### Train the federated model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc718df1",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['ixi']\n",
    "num_rounds = 1\n",
    "\n",
    "exp1 = Experiment(tags=tags,\n",
    "                 model_class=UNetTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc67597",
   "metadata": {},
   "source": [
    "An experiment is a class that orchestrates the training processes that run on different nodes. The experiment has been here initialized with necessary arguments to inform nodes about how to process the training data based on a given model.\n",
    "\n",
    "Let's run the experiment. According to the provided arguments, 1 training round should be completed on the nodes that you created (3 nodes here because there are 3 centers in the case of IXI).\n",
    "Aggregated parameters are saved at the end of the experiment, and their state at every round can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b05f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1085c",
   "metadata": {},
   "source": [
    "Retrieve the federated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44577df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model_ixi = exp1.model_instance()\n",
    "fed_model_ixi.load_state_dict(exp1.aggregated_params()[num_rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae9196",
   "metadata": {},
   "source": [
    "### Test the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32206a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from flamby.utils import evaluate_model_on_tests\n",
    "from flamby.datasets.fed_ixi import (metric as ixi_metric,\n",
    "                                     FedClass as ixi_fed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_ixi_pooled = DataLoader(dataset=ixi_fed(train=False, pooled=True),batch_size=ixi_batch_size)\n",
    "test_dataloader_ixi_client0 = DataLoader(dataset=ixi_fed(center=0, train=False),batch_size=ixi_batch_size)\n",
    "test_dataloader_ixi_client1 = DataLoader(dataset=ixi_fed(center=1, train=False),batch_size=ixi_batch_size)\n",
    "test_dataloader_ixi_client2 = DataLoader(dataset=ixi_fed(center=2, train=False),batch_size=ixi_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021aff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_on_tests(fed_model_ixi,\n",
    "                        [test_dataloader_ixi_pooled,\n",
    "                         test_dataloader_ixi_client0,\n",
    "                         test_dataloader_ixi_client1,\n",
    "                         test_dataloader_ixi_client2],\n",
    "                        ixi_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6e5a3",
   "metadata": {},
   "source": [
    "## 2. Fed-Heart-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd453726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_heart_disease import (Baseline as hd_baseline,\n",
    "                                               BaselineLoss as hd_baseline_loss,\n",
    "                                               Optimizer as hd_optimizer,\n",
    "                                               BATCH_SIZE as hd_batch_size,\n",
    "                                               LR as hd_lr)\n",
    "\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedHeartTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedHeartTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = hd_baseline()\n",
    "        self.loss = hd_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "                'from flamby.datasets.fed_heart_disease import (Baseline as hd_baseline,\\\n",
    "                BaselineLoss as hd_baseline_loss,\\\n",
    "                Optimizer as hd_optimizer)']\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = hd_optimizer(self.parameters())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e81615",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': hd_batch_size,\n",
    "    'lr': hd_lr,\n",
    "    'epochs': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ac086",
   "metadata": {},
   "source": [
    "### Train the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['hd']\n",
    "num_rounds = 1\n",
    "\n",
    "exp2 = Experiment(tags=tags,\n",
    "                 model_class=FedHeartTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd857d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23f5dd",
   "metadata": {},
   "source": [
    "Retrieve the federated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6976a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model_hd = exp2.model_instance()\n",
    "fed_model_hd.load_state_dict(exp2.aggregated_params()[num_rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f40a7",
   "metadata": {},
   "source": [
    "### Test the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_heart_disease import (metric as hd_metric,\n",
    "                                               FedClass as hd_fed)\n",
    "\n",
    "test_dataloader_hd_pooled = DataLoader(dataset=hd_fed(train=False, pooled=True),batch_size=hd_batch_size)\n",
    "test_dataloader_hd_client0 = DataLoader(dataset=hd_fed(center=0, train=False),batch_size=hd_batch_size)\n",
    "test_dataloader_hd_client1 = DataLoader(dataset=hd_fed(center=1, train=False),batch_size=hd_batch_size)\n",
    "test_dataloader_hd_client2 = DataLoader(dataset=hd_fed(center=2, train=False),batch_size=hd_batch_size)\n",
    "test_dataloader_hd_client3 = DataLoader(dataset=hd_fed(center=3, train=False),batch_size=hd_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24395af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_on_tests(fed_model_hd,\n",
    "                        [test_dataloader_hd_pooled,\n",
    "                         test_dataloader_hd_client0,\n",
    "                         test_dataloader_hd_client1,\n",
    "                         test_dataloader_hd_client2,\n",
    "                         test_dataloader_hd_client3],\n",
    "                        hd_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc611220",
   "metadata": {},
   "source": [
    "## 3. Fed-TCGA-BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81850833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_tcga_brca import (Baseline as tc_baseline,\n",
    "                                           BaselineLoss as tc_baseline_loss,\n",
    "                                           Optimizer as tc_optimizer,\n",
    "                                           BATCH_SIZE as tc_batch_size,\n",
    "                                           LR as tc_lr)\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedTcgaBrcaTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedTcgaBrcaTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = tc_baseline()\n",
    "        self.loss = tc_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "               'from flamby.datasets.fed_tcga_brca import (Baseline as tc_baseline,\\\n",
    "                BaselineLoss as tc_baseline_loss,\\\n",
    "                Optimizer as tc_optimizer)']\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = tc_optimizer(self.parameters())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': tc_batch_size,\n",
    "    'lr': tc_lr,\n",
    "    'epochs': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f89c64",
   "metadata": {},
   "source": [
    "### Train the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7063002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['tc']\n",
    "num_rounds = 1\n",
    "\n",
    "exp3 = Experiment(tags=tags,\n",
    "                 model_class=FedTcgaBrcaTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecae04b",
   "metadata": {},
   "source": [
    "Retrieve the federated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model_tc = exp3.model_instance()\n",
    "fed_model_tc.load_state_dict(exp3.aggregated_params()[num_rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc59641",
   "metadata": {},
   "source": [
    "### Test the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_tcga_brca import (metric as tc_metric,\n",
    "                                           FedClass as tc_fed)\n",
    "\n",
    "test_dataloader_tc_pooled = DataLoader(dataset=tc_fed(train=False, pooled=True),batch_size=tc_batch_size)\n",
    "test_dataloader_tc_client0 = DataLoader(dataset=tc_fed(center=0, train=False),batch_size=tc_batch_size)\n",
    "test_dataloader_tc_client1 = DataLoader(dataset=tc_fed(center=1, train=False),batch_size=tc_batch_size)\n",
    "test_dataloader_tc_client2 = DataLoader(dataset=tc_fed(center=2, train=False),batch_size=tc_batch_size)\n",
    "test_dataloader_tc_client3 = DataLoader(dataset=tc_fed(center=3, train=False),batch_size=tc_batch_size)\n",
    "test_dataloader_tc_client4 = DataLoader(dataset=tc_fed(center=4, train=False),batch_size=tc_batch_size)\n",
    "test_dataloader_tc_client5 = DataLoader(dataset=tc_fed(center=5, train=False),batch_size=tc_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_on_tests(fed_model_tc,\n",
    "                        [test_dataloader_tc_pooled,\n",
    "                         test_dataloader_tc_client0,\n",
    "                         test_dataloader_tc_client1,\n",
    "                         test_dataloader_tc_client2,\n",
    "                         test_dataloader_tc_client3,\n",
    "                         test_dataloader_tc_client4,\n",
    "                         test_dataloader_tc_client5],\n",
    "                        tc_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d2ca0",
   "metadata": {},
   "source": [
    "## 4. Fed-Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08101ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_synthetic import (Baseline as sy_baseline,\n",
    "                                           BaselineLoss as sy_baseline_loss,\n",
    "                                           Optimizer as sy_optimizer,\n",
    "                                           BATCH_SIZE as sy_batch_size,\n",
    "                                           LR as sy_lr)\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedSyntheticTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedSyntheticTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = sy_baseline(model_args.get('input_dim', 10), model_args.get('output_dim', 1)) # specific to synthetic use case\n",
    "        self.loss = sy_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "               'from flamby.datasets.fed_synthetic import (Baseline as sy_baseline,\\\n",
    "                BaselineLoss as sy_baseline_loss,\\\n",
    "                Optimizer as sy_optimizer)',]\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = sy_optimizer(self.parameters())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        #this function must return the loss to backward it \n",
    "        output = self.forward(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33826a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': sy_batch_size,\n",
    "    'lr': sy_lr,\n",
    "    'epochs': 5,\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'input_dim': 10,\n",
    "    'output_dim': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67a5af",
   "metadata": {},
   "source": [
    "### Train the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0589792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['sy']\n",
    "num_rounds = 1\n",
    "\n",
    "exp4 = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=FedSyntheticTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1908ea",
   "metadata": {},
   "source": [
    "Retrieve the federated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1802220",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model_sy = exp4.model_instance()\n",
    "fed_model_sy.load_state_dict(exp4.aggregated_params()[num_rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1fc3c",
   "metadata": {},
   "source": [
    "### Test the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_synthetic import (metric as sy_metric,\n",
    "                                           FedClass as sy_fed)\n",
    "\n",
    "test_dataloader_sy_pooled = DataLoader(dataset=sy_fed(train=False, pooled=True),batch_size=sy_batch_size)\n",
    "test_dataloader_sy_client0 = DataLoader(dataset=sy_fed(center=0, train=False),batch_size=sy_batch_size)\n",
    "test_dataloader_sy_client1 = DataLoader(dataset=sy_fed(center=1, train=False),batch_size=sy_batch_size)\n",
    "test_dataloader_sy_client2 = DataLoader(dataset=sy_fed(center=2, train=False),batch_size=sy_batch_size)\n",
    "test_dataloader_sy_client3 = DataLoader(dataset=sy_fed(center=3, train=False),batch_size=sy_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c48ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_on_tests(fed_model_sy,\n",
    "                        [test_dataloader_sy_pooled,\n",
    "                         test_dataloader_sy_client0,\n",
    "                         test_dataloader_sy_client1,\n",
    "                         test_dataloader_sy_client2,\n",
    "                         test_dataloader_sy_client3],\n",
    "                        sy_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a80b2f",
   "metadata": {},
   "source": [
    "## 5. Fed-ISIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_isic2019 import (Baseline as is_baseline,\n",
    "                                          BaselineLoss as is_baseline_loss,\n",
    "                                          Optimizer as is_optimizer,\n",
    "                                          BATCH_SIZE as is_batch_size,\n",
    "                                          LR as is_lr)\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedISICTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedISICTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = is_baseline()\n",
    "        self.loss = is_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "               'from flamby.datasets.fed_isic2019 import (Baseline as is_baseline,\\\n",
    "                BaselineLoss as is_baseline_loss,\\\n",
    "                Optimizer as is_optimizer)',]\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = Adam(self.parameters())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af82b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': is_batch_size,\n",
    "    'lr': is_lr,\n",
    "    'epochs': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fdfe21",
   "metadata": {},
   "source": [
    "### Train the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f765ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['is']\n",
    "num_rounds = 1\n",
    "\n",
    "exp5 = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=FedISICTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp5.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8573611",
   "metadata": {},
   "source": [
    "Retrieve the federated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model_is = exp5.model_instance()\n",
    "fed_model_is.load_state_dict(exp5.aggregated_params()[num_rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324fa47",
   "metadata": {},
   "source": [
    "### Test the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_isic2019 import (metric as is_metric,\n",
    "                                          FedClass as is_fed)\n",
    "\n",
    "test_dataloader_is_pooled = DataLoader(dataset=is_fed(train=False, pooled=True),batch_size=is_batch_size)\n",
    "test_dataloader_is_client0 = DataLoader(dataset=is_fed(center=0, train=False),batch_size=is_batch_size)\n",
    "test_dataloader_is_client1 = DataLoader(dataset=is_fed(center=1, train=False),batch_size=is_batch_size)\n",
    "test_dataloader_is_client2 = DataLoader(dataset=is_fed(center=2, train=False),batch_size=is_batch_size)\n",
    "test_dataloader_is_client3 = DataLoader(dataset=is_fed(center=3, train=False),batch_size=is_batch_size)\n",
    "test_dataloader_is_client4 = DataLoader(dataset=is_fed(center=4, train=False),batch_size=is_batch_size)\n",
    "test_dataloader_is_client5 = DataLoader(dataset=is_fed(center=5, train=False),batch_size=is_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_on_tests(fed_model_is,\n",
    "                        [test_dataloader_is_pooled,\n",
    "                         test_dataloader_is_client0,\n",
    "                         test_dataloader_is_client1,\n",
    "                         test_dataloader_is_client2,\n",
    "                         test_dataloader_is_client3,\n",
    "                         test_dataloader_is_client4,\n",
    "                         test_dataloader_is_client5],\n",
    "                        is_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
